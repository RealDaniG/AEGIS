#!/usr/bin/env python3
"""
Orquestador de Despliegue - AEGIS Framework
Sistema automatizado para despliegue y configuraci√≥n del framework
distribuido en m√∫ltiples entornos y topolog√≠as de red.

Caracter√≠sticas principales:
- Despliegue automatizado multi-entorno
- Configuraci√≥n din√°mica de topolog√≠a
- Gesti√≥n de contenedores Docker
- Orquestaci√≥n con Kubernetes
- Monitoreo de salud del despliegue
- Rollback autom√°tico en caso de fallos
- Escalado horizontal autom√°tico
- Gesti√≥n de secretos y configuraciones
"""

import asyncio
import time
import json
import logging
import yaml
import os
import subprocess
import tempfile
import shutil
import socket
import threading
from typing import Dict, List, Set, Optional, Any, Tuple
from dataclasses import dataclass, asdict, field
from enum import Enum
import docker
import kubernetes
from kubernetes import client, config
import consul
import etcd3
import requests
import paramiko
import jinja2
from pathlib import Path
import hashlib
import base64
from concurrent.futures import ThreadPoolExecutor, as_completed
import psutil
import netifaces

# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DeploymentEnvironment(Enum):
    """Entornos de despliegue"""
    DEVELOPMENT = "development"
    TESTING = "testing"
    STAGING = "staging"
    PRODUCTION = "production"
    EDGE = "edge"

class DeploymentStrategy(Enum):
    """Estrategias de despliegue"""
    ROLLING_UPDATE = "rolling_update"
    BLUE_GREEN = "blue_green"
    CANARY = "canary"
    RECREATE = "recreate"
    A_B_TESTING = "a_b_testing"

class NodeRole(Enum):
    """Roles de nodos en el despliegue"""
    COORDINATOR = "coordinator"
    WORKER = "worker"
    EDGE = "edge"
    BOOTSTRAP = "bootstrap"
    MONITOR = "monitor"

class DeploymentStatus(Enum):
    """Estados del despliegue"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    DEPLOYED = "deployed"
    FAILED = "failed"
    ROLLING_BACK = "rolling_back"
    ROLLED_BACK = "rolled_back"

class HealthStatus(Enum):
    """Estados de salud"""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    UNKNOWN = "unknown"

@dataclass
class NodeConfiguration:
    """Configuraci√≥n de nodo"""
    node_id: str
    role: NodeRole
    hostname: str
    ip_address: str
    port: int
    cpu_cores: int
    memory_gb: int
    storage_gb: int
    gpu_count: int = 0
    network_bandwidth: int = 1000  # Mbps
    zone: str = "default"
    labels: Dict[str, str] = field(default_factory=dict)
    environment_vars: Dict[str, str] = field(default_factory=dict)

@dataclass
class ServiceConfiguration:
    """Configuraci√≥n de servicio"""
    service_name: str
    image: str
    version: str
    replicas: int
    cpu_request: str
    cpu_limit: str
    memory_request: str
    memory_limit: str
    ports: List[int]
    environment_vars: Dict[str, str] = field(default_factory=dict)
    volumes: List[Dict[str, str]] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)
    health_check: Dict[str, Any] = field(default_factory=dict)

@dataclass
class DeploymentConfiguration:
    """Configuraci√≥n completa de despliegue"""
    deployment_id: str
    environment: DeploymentEnvironment
    strategy: DeploymentStrategy
    nodes: List[NodeConfiguration]
    services: List[ServiceConfiguration]
    network_config: Dict[str, Any]
    security_config: Dict[str, Any]
    monitoring_config: Dict[str, Any]
    backup_config: Dict[str, Any] = field(default_factory=dict)
    scaling_config: Dict[str, Any] = field(default_factory=dict)

@dataclass
class DeploymentState:
    """Estado del despliegue"""
    deployment_id: str
    status: DeploymentStatus
    health: HealthStatus
    start_time: float
    last_update: float
    deployed_services: Dict[str, str] = field(default_factory=dict)
    failed_services: List[str] = field(default_factory=list)
    metrics: Dict[str, Any] = field(default_factory=dict)
    logs: List[str] = field(default_factory=list)

class ContainerManager:
    """Gestor de contenedores Docker"""
    
    def __init__(self):
        try:
            self.client = docker.from_env()
            logger.info("‚úÖ Cliente Docker inicializado")
        except Exception as e:
            logger.error(f"‚ùå Error inicializando Docker: {e}")
            self.client = None
    
    async def build_image(self, dockerfile_path: str, image_name: str, tag: str = "latest") -> bool:
        """Construye imagen Docker"""
        try:
            if not self.client:
                raise Exception("Cliente Docker no disponible")
            
            logger.info(f"üî® Construyendo imagen: {image_name}:{tag}")
            
            # Construir imagen
            image, logs = self.client.images.build(
                path=dockerfile_path,
                tag=f"{image_name}:{tag}",
                rm=True,
                forcerm=True
            )
            
            # Procesar logs de construcci√≥n
            for log in logs:
                if 'stream' in log:
                    logger.debug(log['stream'].strip())
            
            logger.info(f"‚úÖ Imagen construida: {image.id[:12]}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error construyendo imagen: {e}")
            return False
    
    async def push_image(self, image_name: str, tag: str, registry: str = None) -> bool:
        """Sube imagen a registro"""
        try:
            if not self.client:
                raise Exception("Cliente Docker no disponible")
            
            full_name = f"{registry}/{image_name}:{tag}" if registry else f"{image_name}:{tag}"
            
            logger.info(f"üì§ Subiendo imagen: {full_name}")
            
            # Subir imagen
            for line in self.client.images.push(full_name, stream=True, decode=True):
                if 'status' in line:
                    logger.debug(f"Push: {line['status']}")
            
            logger.info(f"‚úÖ Imagen subida: {full_name}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error subiendo imagen: {e}")
            return False
    
    async def run_container(self, service_config: ServiceConfiguration, node_config: NodeConfiguration) -> Optional[str]:
        """Ejecuta contenedor"""
        try:
            if not self.client:
                raise Exception("Cliente Docker no disponible")
            
            container_name = f"{service_config.service_name}_{node_config.node_id}"
            
            # Configurar puertos
            port_bindings = {}
            for port in service_config.ports:
                port_bindings[f"{port}/tcp"] = port
            
            # Configurar vol√∫menes
            volumes = {}
            for volume in service_config.volumes:
                volumes[volume["host_path"]] = {
                    "bind": volume["container_path"],
                    "mode": volume.get("mode", "rw")
                }
            
            # Configurar variables de entorno
            environment = {**service_config.environment_vars, **node_config.environment_vars}
            
            logger.info(f"üöÄ Ejecutando contenedor: {container_name}")
            
            # Ejecutar contenedor
            container = self.client.containers.run(
                image=f"{service_config.image}:{service_config.version}",
                name=container_name,
                ports=port_bindings,
                volumes=volumes,
                environment=environment,
                detach=True,
                restart_policy={"Name": "unless-stopped"},
                labels={
                    "aegis.service": service_config.service_name,
                    "aegis.node": node_config.node_id,
                    "aegis.role": node_config.role.value
                }
            )
            
            logger.info(f"‚úÖ Contenedor ejecutado: {container.id[:12]}")
            return container.id
            
        except Exception as e:
            logger.error(f"‚ùå Error ejecutando contenedor: {e}")
            return None
    
    async def stop_container(self, container_id: str) -> bool:
        """Detiene contenedor"""
        try:
            if not self.client:
                return False
            
            container = self.client.containers.get(container_id)
            container.stop(timeout=30)
            container.remove()
            
            logger.info(f"üõë Contenedor detenido: {container_id[:12]}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error deteniendo contenedor: {e}")
            return False

class KubernetesManager:
    """Gestor de Kubernetes"""
    
    def __init__(self, kubeconfig_path: str = None):
        try:
            if kubeconfig_path:
                config.load_kube_config(config_file=kubeconfig_path)
            else:
                config.load_incluster_config()
            
            self.v1 = client.CoreV1Api()
            self.apps_v1 = client.AppsV1Api()
            self.networking_v1 = client.NetworkingV1Api()
            
            logger.info("‚úÖ Cliente Kubernetes inicializado")
            
        except Exception as e:
            logger.error(f"‚ùå Error inicializando Kubernetes: {e}")
            self.v1 = None
            self.apps_v1 = None
            self.networking_v1 = None
    
    async def create_namespace(self, namespace: str) -> bool:
        """Crea namespace"""
        try:
            if not self.v1:
                return False
            
            # Verificar si existe
            try:
                self.v1.read_namespace(name=namespace)
                logger.info(f"üìÅ Namespace ya existe: {namespace}")
                return True
            except client.exceptions.ApiException as e:
                if e.status != 404:
                    raise
            
            # Crear namespace
            namespace_obj = client.V1Namespace(
                metadata=client.V1ObjectMeta(name=namespace)
            )
            
            self.v1.create_namespace(body=namespace_obj)
            logger.info(f"‚úÖ Namespace creado: {namespace}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error creando namespace: {e}")
            return False
    
    async def deploy_service(self, service_config: ServiceConfiguration, namespace: str = "default") -> bool:
        """Despliega servicio en Kubernetes"""
        try:
            if not self.apps_v1:
                return False
            
            # Crear Deployment
            deployment = self._create_deployment_manifest(service_config)
            
            try:
                self.apps_v1.create_namespaced_deployment(
                    namespace=namespace,
                    body=deployment
                )
                logger.info(f"‚úÖ Deployment creado: {service_config.service_name}")
            except client.exceptions.ApiException as e:
                if e.status == 409:  # Already exists
                    self.apps_v1.patch_namespaced_deployment(
                        name=service_config.service_name,
                        namespace=namespace,
                        body=deployment
                    )
                    logger.info(f"üîÑ Deployment actualizado: {service_config.service_name}")
                else:
                    raise
            
            # Crear Service
            service = self._create_service_manifest(service_config)
            
            try:
                self.v1.create_namespaced_service(
                    namespace=namespace,
                    body=service
                )
                logger.info(f"‚úÖ Service creado: {service_config.service_name}")
            except client.exceptions.ApiException as e:
                if e.status == 409:  # Already exists
                    self.v1.patch_namespaced_service(
                        name=service_config.service_name,
                        namespace=namespace,
                        body=service
                    )
                    logger.info(f"üîÑ Service actualizado: {service_config.service_name}")
                else:
                    raise
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error desplegando servicio: {e}")
            return False
    
    def _create_deployment_manifest(self, service_config: ServiceConfiguration) -> client.V1Deployment:
        """Crea manifiesto de Deployment"""
        # Configurar contenedor
        container = client.V1Container(
            name=service_config.service_name,
            image=f"{service_config.image}:{service_config.version}",
            ports=[client.V1ContainerPort(container_port=port) for port in service_config.ports],
            env=[client.V1EnvVar(name=k, value=v) for k, v in service_config.environment_vars.items()],
            resources=client.V1ResourceRequirements(
                requests={
                    "cpu": service_config.cpu_request,
                    "memory": service_config.memory_request
                },
                limits={
                    "cpu": service_config.cpu_limit,
                    "memory": service_config.memory_limit
                }
            )
        )
        
        # Configurar health check si est√° definido
        if service_config.health_check:
            if "http" in service_config.health_check:
                http_check = service_config.health_check["http"]
                container.liveness_probe = client.V1Probe(
                    http_get=client.V1HTTPGetAction(
                        path=http_check["path"],
                        port=http_check["port"]
                    ),
                    initial_delay_seconds=http_check.get("initial_delay", 30),
                    period_seconds=http_check.get("period", 10)
                )
        
        # Configurar Pod template
        pod_template = client.V1PodTemplateSpec(
            metadata=client.V1ObjectMeta(
                labels={"app": service_config.service_name}
            ),
            spec=client.V1PodSpec(containers=[container])
        )
        
        # Configurar Deployment spec
        deployment_spec = client.V1DeploymentSpec(
            replicas=service_config.replicas,
            selector=client.V1LabelSelector(
                match_labels={"app": service_config.service_name}
            ),
            template=pod_template
        )
        
        # Crear Deployment
        deployment = client.V1Deployment(
            api_version="apps/v1",
            kind="Deployment",
            metadata=client.V1ObjectMeta(name=service_config.service_name),
            spec=deployment_spec
        )
        
        return deployment
    
    def _create_service_manifest(self, service_config: ServiceConfiguration) -> client.V1Service:
        """Crea manifiesto de Service"""
        # Configurar puertos
        ports = [
            client.V1ServicePort(
                port=port,
                target_port=port,
                protocol="TCP"
            ) for port in service_config.ports
        ]
        
        # Configurar Service spec
        service_spec = client.V1ServiceSpec(
            selector={"app": service_config.service_name},
            ports=ports,
            type="ClusterIP"
        )
        
        # Crear Service
        service = client.V1Service(
            api_version="v1",
            kind="Service",
            metadata=client.V1ObjectMeta(name=service_config.service_name),
            spec=service_spec
        )
        
        return service
    
    async def get_deployment_status(self, service_name: str, namespace: str = "default") -> Dict[str, Any]:
        """Obtiene estado del deployment"""
        try:
            if not self.apps_v1:
                return {"status": "unknown", "error": "Kubernetes no disponible"}
            
            deployment = self.apps_v1.read_namespaced_deployment(
                name=service_name,
                namespace=namespace
            )
            
            status = {
                "name": service_name,
                "namespace": namespace,
                "replicas": deployment.spec.replicas,
                "ready_replicas": deployment.status.ready_replicas or 0,
                "available_replicas": deployment.status.available_replicas or 0,
                "updated_replicas": deployment.status.updated_replicas or 0,
                "conditions": []
            }
            
            if deployment.status.conditions:
                for condition in deployment.status.conditions:
                    status["conditions"].append({
                        "type": condition.type,
                        "status": condition.status,
                        "reason": condition.reason,
                        "message": condition.message
                    })
            
            return status
            
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo estado de deployment: {e}")
            return {"status": "error", "error": str(e)}

class ConfigurationManager:
    """Gestor de configuraciones"""
    
    def __init__(self, config_dir: str = "./config"):
        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(exist_ok=True)
        self.template_env = jinja2.Environment(
            loader=jinja2.FileSystemLoader(str(self.config_dir / "templates")),
            autoescape=jinja2.select_autoescape(['html', 'xml'])
        )
    
    def generate_docker_compose(self, deployment_config: DeploymentConfiguration) -> str:
        """Genera archivo docker-compose.yml"""
        compose_config = {
            "version": "3.8",
            "services": {},
            "networks": {
                "aegis-network": {
                    "driver": "bridge",
                    "ipam": {
                        "config": [{"subnet": deployment_config.network_config.get("subnet", "172.20.0.0/16")}]
                    }
                }
            },
            "volumes": {}
        }
        
        # Configurar servicios
        for service in deployment_config.services:
            service_config = {
                "image": f"{service.image}:{service.version}",
                "container_name": f"{service.service_name}_{deployment_config.deployment_id}",
                "restart": "unless-stopped",
                "networks": ["aegis-network"],
                "environment": service.environment_vars,
                "ports": [f"{port}:{port}" for port in service.ports]
            }
            
            # Configurar vol√∫menes
            if service.volumes:
                service_config["volumes"] = [
                    f"{vol['host_path']}:{vol['container_path']}:{vol.get('mode', 'rw')}"
                    for vol in service.volumes
                ]
            
            # Configurar dependencias
            if service.dependencies:
                service_config["depends_on"] = service.dependencies
            
            # Configurar health check
            if service.health_check and "http" in service.health_check:
                http_check = service.health_check["http"]
                service_config["healthcheck"] = {
                    "test": f"curl -f http://localhost:{http_check['port']}{http_check['path']} || exit 1",
                    "interval": f"{http_check.get('period', 10)}s",
                    "timeout": "5s",
                    "retries": 3,
                    "start_period": f"{http_check.get('initial_delay', 30)}s"
                }
            
            compose_config["services"][service.service_name] = service_config
        
        # Escribir archivo
        compose_file = self.config_dir / f"docker-compose-{deployment_config.deployment_id}.yml"
        with open(compose_file, 'w') as f:
            yaml.dump(compose_config, f, default_flow_style=False, indent=2)
        
        logger.info(f"‚úÖ Docker Compose generado: {compose_file}")
        return str(compose_file)
    
    def generate_kubernetes_manifests(self, deployment_config: DeploymentConfiguration) -> str:
        """Genera manifiestos de Kubernetes"""
        manifests_dir = self.config_dir / f"k8s-{deployment_config.deployment_id}"
        manifests_dir.mkdir(exist_ok=True)
        
        # Generar namespace
        namespace_manifest = {
            "apiVersion": "v1",
            "kind": "Namespace",
            "metadata": {
                "name": f"aegis-{deployment_config.deployment_id}"
            }
        }
        
        with open(manifests_dir / "namespace.yaml", 'w') as f:
            yaml.dump(namespace_manifest, f, default_flow_style=False)
        
        # Generar manifiestos para cada servicio
        for service in deployment_config.services:
            # Deployment
            deployment_manifest = {
                "apiVersion": "apps/v1",
                "kind": "Deployment",
                "metadata": {
                    "name": service.service_name,
                    "namespace": f"aegis-{deployment_config.deployment_id}"
                },
                "spec": {
                    "replicas": service.replicas,
                    "selector": {
                        "matchLabels": {"app": service.service_name}
                    },
                    "template": {
                        "metadata": {
                            "labels": {"app": service.service_name}
                        },
                        "spec": {
                            "containers": [{
                                "name": service.service_name,
                                "image": f"{service.image}:{service.version}",
                                "ports": [{"containerPort": port} for port in service.ports],
                                "env": [{"name": k, "value": v} for k, v in service.environment_vars.items()],
                                "resources": {
                                    "requests": {
                                        "cpu": service.cpu_request,
                                        "memory": service.memory_request
                                    },
                                    "limits": {
                                        "cpu": service.cpu_limit,
                                        "memory": service.memory_limit
                                    }
                                }
                            }]
                        }
                    }
                }
            }
            
            with open(manifests_dir / f"{service.service_name}-deployment.yaml", 'w') as f:
                yaml.dump(deployment_manifest, f, default_flow_style=False)
            
            # Service
            service_manifest = {
                "apiVersion": "v1",
                "kind": "Service",
                "metadata": {
                    "name": service.service_name,
                    "namespace": f"aegis-{deployment_config.deployment_id}"
                },
                "spec": {
                    "selector": {"app": service.service_name},
                    "ports": [{"port": port, "targetPort": port} for port in service.ports],
                    "type": "ClusterIP"
                }
            }
            
            with open(manifests_dir / f"{service.service_name}-service.yaml", 'w') as f:
                yaml.dump(service_manifest, f, default_flow_style=False)
        
        logger.info(f"‚úÖ Manifiestos K8s generados: {manifests_dir}")
        return str(manifests_dir)
    
    def generate_monitoring_config(self, deployment_config: DeploymentConfiguration) -> str:
        """Genera configuraci√≥n de monitoreo"""
        monitoring_config = {
            "prometheus": {
                "scrape_configs": []
            },
            "grafana": {
                "dashboards": [],
                "datasources": []
            },
            "alertmanager": {
                "rules": []
            }
        }
        
        # Configurar scraping de Prometheus
        for service in deployment_config.services:
            if "metrics_port" in service.environment_vars:
                scrape_config = {
                    "job_name": service.service_name,
                    "static_configs": [{
                        "targets": [f"{service.service_name}:{service.environment_vars['metrics_port']}"]
                    }],
                    "scrape_interval": "15s",
                    "metrics_path": "/metrics"
                }
                monitoring_config["prometheus"]["scrape_configs"].append(scrape_config)
        
        # Escribir configuraci√≥n
        monitoring_file = self.config_dir / f"monitoring-{deployment_config.deployment_id}.yml"
        with open(monitoring_file, 'w') as f:
            yaml.dump(monitoring_config, f, default_flow_style=False, indent=2)
        
        logger.info(f"‚úÖ Configuraci√≥n de monitoreo generada: {monitoring_file}")
        return str(monitoring_file)

class HealthChecker:
    """Verificador de salud de servicios"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.timeout = 10
    
    async def check_service_health(self, service_config: ServiceConfiguration, node_config: NodeConfiguration) -> Dict[str, Any]:
        """Verifica salud de servicio"""
        health_result = {
            "service": service_config.service_name,
            "node": node_config.node_id,
            "status": HealthStatus.UNKNOWN,
            "checks": [],
            "response_time": None,
            "error": None
        }
        
        try:
            # Verificar health check HTTP si est√° configurado
            if service_config.health_check and "http" in service_config.health_check:
                http_check = service_config.health_check["http"]
                url = f"http://{node_config.ip_address}:{http_check['port']}{http_check['path']}"
                
                start_time = time.time()
                response = self.session.get(url)
                response_time = time.time() - start_time
                
                health_result["response_time"] = response_time
                
                if response.status_code == 200:
                    health_result["status"] = HealthStatus.HEALTHY
                    health_result["checks"].append({
                        "type": "http",
                        "status": "passed",
                        "response_code": response.status_code,
                        "response_time": response_time
                    })
                else:
                    health_result["status"] = HealthStatus.UNHEALTHY
                    health_result["checks"].append({
                        "type": "http",
                        "status": "failed",
                        "response_code": response.status_code,
                        "response_time": response_time
                    })
            
            # Verificar conectividad de puertos
            for port in service_config.ports:
                port_check = self._check_port_connectivity(node_config.ip_address, port)
                health_result["checks"].append(port_check)
                
                if port_check["status"] == "failed" and health_result["status"] != HealthStatus.UNHEALTHY:
                    health_result["status"] = HealthStatus.DEGRADED
            
            # Si no hay checks espec√≠ficos, verificar conectividad b√°sica
            if not health_result["checks"]:
                basic_check = self._check_basic_connectivity(node_config.ip_address)
                health_result["checks"].append(basic_check)
                
                if basic_check["status"] == "passed":
                    health_result["status"] = HealthStatus.HEALTHY
                else:
                    health_result["status"] = HealthStatus.UNHEALTHY
            
        except Exception as e:
            health_result["status"] = HealthStatus.UNHEALTHY
            health_result["error"] = str(e)
            health_result["checks"].append({
                "type": "exception",
                "status": "failed",
                "error": str(e)
            })
        
        return health_result
    
    def _check_port_connectivity(self, ip_address: str, port: int) -> Dict[str, Any]:
        """Verifica conectividad de puerto"""
        try:
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(5)
            result = sock.connect_ex((ip_address, port))
            sock.close()
            
            if result == 0:
                return {
                    "type": "port",
                    "port": port,
                    "status": "passed",
                    "message": f"Puerto {port} accesible"
                }
            else:
                return {
                    "type": "port",
                    "port": port,
                    "status": "failed",
                    "message": f"Puerto {port} no accesible"
                }
        except Exception as e:
            return {
                "type": "port",
                "port": port,
                "status": "failed",
                "error": str(e)
            }
    
    def _check_basic_connectivity(self, ip_address: str) -> Dict[str, Any]:
        """Verifica conectividad b√°sica"""
        try:
            # Ping b√°sico usando socket
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(5)
            result = sock.connect_ex((ip_address, 22))  # SSH port como proxy de conectividad
            sock.close()
            
            return {
                "type": "connectivity",
                "status": "passed" if result == 0 else "failed",
                "message": f"Conectividad a {ip_address}: {'OK' if result == 0 else 'FAIL'}"
            }
        except Exception as e:
            return {
                "type": "connectivity",
                "status": "failed",
                "error": str(e)
            }

class DeploymentOrchestrator:
    """Orquestador principal de despliegue"""
    
    def __init__(self, config_dir: str = "./config"):
        self.config_manager = ConfigurationManager(config_dir)
        self.container_manager = ContainerManager()
        self.k8s_manager = KubernetesManager()
        self.health_checker = HealthChecker()
        
        self.deployments: Dict[str, DeploymentState] = {}
        self.deployment_configs: Dict[str, DeploymentConfiguration] = {}
        
        # Configurar directorio de trabajo
        self.work_dir = Path("./deployments")
        self.work_dir.mkdir(exist_ok=True)
        
        logger.info("üöÄ Orquestador de Despliegue inicializado")
    
    async def deploy(self, deployment_config: DeploymentConfiguration) -> bool:
        """Ejecuta despliegue completo"""
        deployment_id = deployment_config.deployment_id
        
        try:
            logger.info(f"üöÄ Iniciando despliegue: {deployment_id}")
            
            # Inicializar estado
            deployment_state = DeploymentState(
                deployment_id=deployment_id,
                status=DeploymentStatus.PENDING,
                health=HealthStatus.UNKNOWN,
                start_time=time.time(),
                last_update=time.time()
            )
            
            self.deployments[deployment_id] = deployment_state
            self.deployment_configs[deployment_id] = deployment_config
            
            # Actualizar estado
            await self._update_deployment_status(deployment_id, DeploymentStatus.IN_PROGRESS)
            
            # Validar configuraci√≥n
            if not await self._validate_deployment_config(deployment_config):
                await self._update_deployment_status(deployment_id, DeploymentStatus.FAILED)
                return False
            
            # Preparar entorno
            if not await self._prepare_deployment_environment(deployment_config):
                await self._update_deployment_status(deployment_id, DeploymentStatus.FAILED)
                return False
            
            # Ejecutar estrategia de despliegue
            success = await self._execute_deployment_strategy(deployment_config)
            
            if success:
                await self._update_deployment_status(deployment_id, DeploymentStatus.DEPLOYED)
                
                # Verificar salud post-despliegue
                await self._post_deployment_health_check(deployment_config)
                
                logger.info(f"‚úÖ Despliegue completado: {deployment_id}")
                return True
            else:
                await self._update_deployment_status(deployment_id, DeploymentStatus.FAILED)
                
                # Intentar rollback autom√°tico
                if deployment_config.environment != DeploymentEnvironment.DEVELOPMENT:
                    await self._rollback_deployment(deployment_id)
                
                logger.error(f"‚ùå Despliegue fallido: {deployment_id}")
                return False
                
        except Exception as e:
            logger.error(f"üí• Error en despliegue {deployment_id}: {e}")
            await self._update_deployment_status(deployment_id, DeploymentStatus.FAILED)
            return False
    
    async def _validate_deployment_config(self, config: DeploymentConfiguration) -> bool:
        """Valida configuraci√≥n de despliegue"""
        try:
            logger.info("üîç Validando configuraci√≥n de despliegue")
            
            # Validar nodos
            if not config.nodes:
                logger.error("‚ùå No hay nodos configurados")
                return False
            
            # Validar servicios
            if not config.services:
                logger.error("‚ùå No hay servicios configurados")
                return False
            
            # Validar conectividad de nodos
            for node in config.nodes:
                if not await self._validate_node_connectivity(node):
                    logger.error(f"‚ùå Nodo no accesible: {node.node_id}")
                    return False
            
            # Validar dependencias de servicios
            service_names = {service.service_name for service in config.services}
            for service in config.services:
                for dependency in service.dependencies:
                    if dependency not in service_names:
                        logger.error(f"‚ùå Dependencia no encontrada: {dependency} para {service.service_name}")
                        return False
            
            # Validar recursos
            for node in config.nodes:
                if not await self._validate_node_resources(node, config.services):
                    logger.error(f"‚ùå Recursos insuficientes en nodo: {node.node_id}")
                    return False
            
            logger.info("‚úÖ Configuraci√≥n validada")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error validando configuraci√≥n: {e}")
            return False
    
    async def _validate_node_connectivity(self, node: NodeConfiguration) -> bool:
        """Valida conectividad de nodo"""
        try:
            # Verificar ping b√°sico
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(5)
            result = sock.connect_ex((node.ip_address, 22))
            sock.close()
            
            return result == 0
            
        except Exception as e:
            logger.error(f"‚ùå Error verificando conectividad de {node.node_id}: {e}")
            return False
    
    async def _validate_node_resources(self, node: NodeConfiguration, services: List[ServiceConfiguration]) -> bool:
        """Valida recursos de nodo"""
        try:
            # Calcular recursos requeridos para servicios en este nodo
            required_cpu = 0
            required_memory = 0
            
            for service in services:
                # Parsear requests de CPU (ej: "100m" = 0.1 cores)
                cpu_request = service.cpu_request
                if cpu_request.endswith('m'):
                    required_cpu += int(cpu_request[:-1]) / 1000
                else:
                    required_cpu += float(cpu_request)
                
                # Parsear requests de memoria (ej: "256Mi" = 256 MB)
                memory_request = service.memory_request
                if memory_request.endswith('Mi'):
                    required_memory += int(memory_request[:-2])
                elif memory_request.endswith('Gi'):
                    required_memory += int(memory_request[:-2]) * 1024
                else:
                    required_memory += int(memory_request)
            
            # Verificar disponibilidad (con margen del 20%)
            available_cpu = node.cpu_cores * 0.8
            available_memory = node.memory_gb * 1024 * 0.8
            
            if required_cpu > available_cpu:
                logger.warning(f"[WARN] CPU insuficiente en {node.node_id}: {required_cpu} > {available_cpu}")
                return False
            
            if required_memory > available_memory:
                logger.warning(f"[WARN] Memoria insuficiente en {node.node_id}: {required_memory} > {available_memory}")
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error validando recursos de {node.node_id}: {e}")
            return False
    
    async def _prepare_deployment_environment(self, config: DeploymentConfiguration) -> bool:
        """Prepara entorno de despliegue"""
        try:
            logger.info("üîß Preparando entorno de despliegue")
            
            # Generar archivos de configuraci√≥n
            if config.environment == DeploymentEnvironment.DEVELOPMENT:
                compose_file = self.config_manager.generate_docker_compose(config)
                logger.info(f"üìÑ Docker Compose: {compose_file}")
            else:
                k8s_manifests = self.config_manager.generate_kubernetes_manifests(config)
                logger.info(f"üìÑ Manifiestos K8s: {k8s_manifests}")
            
            # Generar configuraci√≥n de monitoreo
            monitoring_config = self.config_manager.generate_monitoring_config(config)
            logger.info(f"üìä Configuraci√≥n de monitoreo: {monitoring_config}")
            
            # Preparar directorios de trabajo
            deployment_dir = self.work_dir / config.deployment_id
            deployment_dir.mkdir(exist_ok=True)
            
            # Crear directorios para logs y datos
            (deployment_dir / "logs").mkdir(exist_ok=True)
            (deployment_dir / "data").mkdir(exist_ok=True)
            
            logger.info("‚úÖ Entorno preparado")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error preparando entorno: {e}")
            return False
    
    async def _execute_deployment_strategy(self, config: DeploymentConfiguration) -> bool:
        """Ejecuta estrategia de despliegue"""
        try:
            logger.info(f"üéØ Ejecutando estrategia: {config.strategy.value}")
            
            if config.strategy == DeploymentStrategy.ROLLING_UPDATE:
                return await self._rolling_update_deployment(config)
            elif config.strategy == DeploymentStrategy.BLUE_GREEN:
                return await self._blue_green_deployment(config)
            elif config.strategy == DeploymentStrategy.CANARY:
                return await self._canary_deployment(config)
            elif config.strategy == DeploymentStrategy.RECREATE:
                return await self._recreate_deployment(config)
            else:
                logger.error(f"‚ùå Estrategia no soportada: {config.strategy.value}")
                return False
                
        except Exception as e:
            logger.error(f"‚ùå Error ejecutando estrategia: {e}")
            return False
    
    async def _rolling_update_deployment(self, config: DeploymentConfiguration) -> bool:
        """Despliegue con rolling update"""
        try:
            logger.info("üîÑ Ejecutando rolling update")
            
            # Ordenar servicios por dependencias
            ordered_services = self._topological_sort_services(config.services)
            
            # Desplegar servicios uno por uno
            for service in ordered_services:
                logger.info(f"üöÄ Desplegando servicio: {service.service_name}")
                
                if config.environment == DeploymentEnvironment.DEVELOPMENT:
                    # Usar Docker para desarrollo
                    success = await self._deploy_service_docker(service, config.nodes[0])
                else:
                    # Usar Kubernetes para otros entornos
                    success = await self._deploy_service_kubernetes(service, config)
                
                if not success:
                    logger.error(f"‚ùå Fallo desplegando {service.service_name}")
                    return False
                
                # Esperar a que el servicio est√© saludable
                if not await self._wait_for_service_health(service, config.nodes[0]):
                    logger.error(f"‚ùå Servicio no saludable: {service.service_name}")
                    return False
                
                # Actualizar estado
                self.deployments[config.deployment_id].deployed_services[service.service_name] = "deployed"
            
            logger.info("‚úÖ Rolling update completado")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error en rolling update: {e}")
            return False
    
    async def _blue_green_deployment(self, config: DeploymentConfiguration) -> bool:
        """Despliegue blue-green"""
        try:
            logger.info("üîµüü¢ Ejecutando despliegue blue-green")
            
            # Crear entorno "green" (nuevo)
            green_config = self._create_green_environment(config)
            
            # Desplegar en entorno green
            if not await self._deploy_to_environment(green_config, "green"):
                return False
            
            # Verificar salud del entorno green
            if not await self._verify_environment_health(green_config):
                return False
            
            # Cambiar tr√°fico de blue a green
            if not await self._switch_traffic(config, green_config):
                return False
            
            # Limpiar entorno blue anterior
            await self._cleanup_blue_environment(config)
            
            logger.info("‚úÖ Despliegue blue-green completado")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error en despliegue blue-green: {e}")
            return False
    
    async def _canary_deployment(self, config: DeploymentConfiguration) -> bool:
        """Despliegue canary"""
        try:
            logger.info("üê§ Ejecutando despliegue canary")
            
            # Desplegar versi√≥n canary (5% del tr√°fico)
            canary_config = self._create_canary_environment(config, traffic_percentage=5)
            
            if not await self._deploy_to_environment(canary_config, "canary"):
                return False
            
            # Monitorear m√©tricas por 5 minutos
            if not await self._monitor_canary_metrics(canary_config, duration=300):
                logger.error("‚ùå M√©tricas de canary fallaron")
                await self._rollback_canary(canary_config)
                return False
            
            # Incrementar tr√°fico gradualmente
            for percentage in [10, 25, 50, 100]:
                logger.info(f"üìà Incrementando tr√°fico canary a {percentage}%")
                
                if not await self._update_canary_traffic(canary_config, percentage):
                    await self._rollback_canary(canary_config)
                    return False
                
                # Monitorear por 2 minutos en cada incremento
                if not await self._monitor_canary_metrics(canary_config, duration=120):
                    await self._rollback_canary(canary_config)
                    return False
            
            # Promover canary a producci√≥n
            await self._promote_canary_to_production(canary_config)
            
            logger.info("‚úÖ Despliegue canary completado")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error en despliegue canary: {e}")
            return False
    
    async def _recreate_deployment(self, config: DeploymentConfiguration) -> bool:
        """Despliegue recreate (detener todo y recrear)"""
        try:
            logger.info("üîÑ Ejecutando despliegue recreate")
            
            # Detener servicios existentes
            await self._stop_existing_services(config)
            
            # Esperar a que se detengan completamente
            await asyncio.sleep(10)
            
            # Desplegar nuevas versiones
            return await self._rolling_update_deployment(config)
            
        except Exception as e:
            logger.error(f"‚ùå Error en despliegue recreate: {e}")
            return False
    
    async def _deploy_service_docker(self, service: ServiceConfiguration, node: NodeConfiguration) -> bool:
        """Despliega servicio usando Docker"""
        try:
            container_id = await self.container_manager.run_container(service, node)
            return container_id is not None
            
        except Exception as e:
            logger.error(f"‚ùå Error desplegando servicio Docker: {e}")
            return False
    
    async def _deploy_service_kubernetes(self, service: ServiceConfiguration, config: DeploymentConfiguration) -> bool:
        """Despliega servicio usando Kubernetes"""
        try:
            namespace = f"aegis-{config.deployment_id}"
            
            # Crear namespace si no existe
            await self.k8s_manager.create_namespace(namespace)
            
            # Desplegar servicio
            return await self.k8s_manager.deploy_service(service, namespace)
            
        except Exception as e:
            logger.error(f"‚ùå Error desplegando servicio K8s: {e}")
            return False
    
    async def _wait_for_service_health(self, service: ServiceConfiguration, node: NodeConfiguration, timeout: int = 300) -> bool:
        """Espera a que el servicio est√© saludable"""
        try:
            start_time = time.time()
            
            while time.time() - start_time < timeout:
                health_result = await self.health_checker.check_service_health(service, node)
                
                if health_result["status"] == HealthStatus.HEALTHY:
                    logger.info(f"‚úÖ Servicio saludable: {service.service_name}")
                    return True
                
                logger.info(f"‚è≥ Esperando salud de {service.service_name}...")
                await asyncio.sleep(10)
            
            logger.error(f"‚è∞ Timeout esperando salud de {service.service_name}")
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Error verificando salud: {e}")
            return False
    
    def _topological_sort_services(self, services: List[ServiceConfiguration]) -> List[ServiceConfiguration]:
        """Ordena servicios por dependencias usando ordenamiento topol√≥gico"""
        # Crear grafo de dependencias
        graph = {service.service_name: service.dependencies for service in services}
        service_map = {service.service_name: service for service in services}
        
        # Algoritmo de Kahn para ordenamiento topol√≥gico
        in_degree = {name: 0 for name in graph}
        for dependencies in graph.values():
            for dep in dependencies:
                if dep in in_degree:
                    in_degree[dep] += 1
        
        queue = [name for name, degree in in_degree.items() if degree == 0]
        result = []
        
        while queue:
            current = queue.pop(0)
            result.append(service_map[current])
            
            for neighbor in graph[current]:
                if neighbor in in_degree:
                    in_degree[neighbor] -= 1
                    if in_degree[neighbor] == 0:
                        queue.append(neighbor)
        
        return result
    
    async def _post_deployment_health_check(self, config: DeploymentConfiguration):
        """Verificaci√≥n de salud post-despliegue"""
        try:
            logger.info("üè• Verificando salud post-despliegue")
            
            health_results = []
            
            # Verificar cada servicio en cada nodo
            for service in config.services:
                for node in config.nodes:
                    health_result = await self.health_checker.check_service_health(service, node)
                    health_results.append(health_result)
            
            # Actualizar estado de salud del despliegue
            healthy_services = sum(1 for result in health_results if result["status"] == HealthStatus.HEALTHY)
            total_checks = len(health_results)
            
            if healthy_services == total_checks:
                self.deployments[config.deployment_id].health = HealthStatus.HEALTHY
            elif healthy_services > total_checks * 0.7:
                self.deployments[config.deployment_id].health = HealthStatus.DEGRADED
            else:
                self.deployments[config.deployment_id].health = HealthStatus.UNHEALTHY
            
            # Almacenar m√©tricas de salud
            self.deployments[config.deployment_id].metrics["health_check"] = {
                "healthy_services": healthy_services,
                "total_checks": total_checks,
                "health_ratio": healthy_services / total_checks,
                "detailed_results": health_results
            }
            
            logger.info(f"üè• Salud del despliegue: {self.deployments[config.deployment_id].health.value}")
            
        except Exception as e:
            logger.error(f"‚ùå Error en verificaci√≥n de salud: {e}")
            self.deployments[config.deployment_id].health = HealthStatus.UNKNOWN
    
    async def _update_deployment_status(self, deployment_id: str, status: DeploymentStatus):
        """Actualiza estado del despliegue"""
        if deployment_id in self.deployments:
            self.deployments[deployment_id].status = status
            self.deployments[deployment_id].last_update = time.time()
            
            logger.info(f"üìä Estado de despliegue {deployment_id}: {status.value}")
    
    async def _rollback_deployment(self, deployment_id: str) -> bool:
        """Ejecuta rollback del despliegue"""
        try:
            logger.info(f"üîô Iniciando rollback: {deployment_id}")
            
            await self._update_deployment_status(deployment_id, DeploymentStatus.ROLLING_BACK)
            
            # Implementar l√≥gica de rollback espec√≠fica
            # Por ahora, simplemente detener servicios fallidos
            config = self.deployment_configs[deployment_id]
            await self._stop_existing_services(config)
            
            await self._update_deployment_status(deployment_id, DeploymentStatus.ROLLED_BACK)
            
            logger.info(f"‚úÖ Rollback completado: {deployment_id}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå Error en rollback: {e}")
            return False
    
    async def _stop_existing_services(self, config: DeploymentConfiguration):
        """Detiene servicios existentes"""
        try:
            logger.info("üõë Deteniendo servicios existentes")
            
            if config.environment == DeploymentEnvironment.DEVELOPMENT:
                # Detener contenedores Docker
                if self.container_manager.client:
                    containers = self.container_manager.client.containers.list(
                        filters={"label": f"aegis.deployment={config.deployment_id}"}
                    )
                    
                    for container in containers:
                        container.stop(timeout=30)
                        container.remove()
                        logger.info(f"üõë Contenedor detenido: {container.name}")
            
            else:
                # Detener servicios de Kubernetes
                if self.k8s_manager.apps_v1:
                    namespace = f"aegis-{config.deployment_id}"
                    
                    # Escalar deployments a 0
                    deployments = self.k8s_manager.apps_v1.list_namespaced_deployment(namespace=namespace)
                    
                    for deployment in deployments.items:
                        deployment.spec.replicas = 0
                        self.k8s_manager.apps_v1.patch_namespaced_deployment(
                            name=deployment.metadata.name,
                            namespace=namespace,
                            body=deployment
                        )
                        logger.info(f"üõë Deployment escalado a 0: {deployment.metadata.name}")
            
        except Exception as e:
            logger.error(f"‚ùå Error deteniendo servicios: {e}")
    
    # M√©todos auxiliares para estrategias avanzadas (implementaci√≥n b√°sica)
    def _create_green_environment(self, config: DeploymentConfiguration) -> DeploymentConfiguration:
        """Crea configuraci√≥n para entorno green"""
        green_config = config
        green_config.deployment_id = f"{config.deployment_id}-green"
        return green_config
    
    async def _deploy_to_environment(self, config: DeploymentConfiguration, env_name: str) -> bool:
        """Despliega a entorno espec√≠fico"""
        return await self._rolling_update_deployment(config)
    
    async def _verify_environment_health(self, config: DeploymentConfiguration) -> bool:
        """Verifica salud del entorno"""
        await self._post_deployment_health_check(config)
        return self.deployments[config.deployment_id].health in [HealthStatus.HEALTHY, HealthStatus.DEGRADED]
    
    async def _switch_traffic(self, old_config: DeploymentConfiguration, new_config: DeploymentConfiguration) -> bool:
        """Cambia tr√°fico entre entornos"""
        logger.info("üîÑ Cambiando tr√°fico a nuevo entorno")
        return True
    
    async def _cleanup_blue_environment(self, config: DeploymentConfiguration):
        """Limpia entorno blue anterior"""
        logger.info("üßπ Limpiando entorno anterior")
    
    def _create_canary_environment(self, config: DeploymentConfiguration, traffic_percentage: int) -> DeploymentConfiguration:
        """Crea configuraci√≥n para entorno canary"""
        canary_config = config
        canary_config.deployment_id = f"{config.deployment_id}-canary"
        return canary_config
    
    async def _monitor_canary_metrics(self, config: DeploymentConfiguration, duration: int) -> bool:
        """Monitorea m√©tricas de canary"""
        logger.info(f"üìä Monitoreando canary por {duration}s")
        await asyncio.sleep(duration)
        return True
    
    async def _update_canary_traffic(self, config: DeploymentConfiguration, percentage: int) -> bool:
        """Actualiza porcentaje de tr√°fico canary"""
        logger.info(f"üìà Actualizando tr√°fico canary: {percentage}%")
        return True
    
    async def _rollback_canary(self, config: DeploymentConfiguration):
        """Rollback de canary"""
        logger.info("üîô Rollback de canary")
    
    async def _promote_canary_to_production(self, config: DeploymentConfiguration):
        """Promueve canary a producci√≥n"""
        logger.info("üéâ Promoviendo canary a producci√≥n")
    
    def get_deployment_status(self, deployment_id: str) -> Optional[DeploymentState]:
        """Obtiene estado del despliegue"""
        return self.deployments.get(deployment_id)
    
    def list_deployments(self) -> Dict[str, DeploymentState]:
        """Lista todos los despliegues"""
        return self.deployments.copy()
    
    async def cleanup_deployment(self, deployment_id: str) -> bool:
        """Limpia despliegue"""
        try:
            if deployment_id in self.deployment_configs:
                config = self.deployment_configs[deployment_id]
                await self._stop_existing_services(config)
                
                # Limpiar directorios
                deployment_dir = self.work_dir / deployment_id
                if deployment_dir.exists():
                    shutil.rmtree(deployment_dir)
                
                # Limpiar estado
                del self.deployments[deployment_id]
                del self.deployment_configs[deployment_id]
                
                logger.info(f"üßπ Despliegue limpiado: {deployment_id}")
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"‚ùå Error limpiando despliegue: {e}")
            return False

# Funci√≥n principal para demostraci√≥n
async def main():
    """Funci√≥n principal de demostraci√≥n"""
    try:
        print("üöÄ Iniciando Orquestador de Despliegue - AEGIS Framework")
        
        # Crear orquestador
        orchestrator = DeploymentOrchestrator()
        
        # Configuraci√≥n de ejemplo
        deployment_config = DeploymentConfiguration(
            deployment_id="aegis-demo-001",
            environment=DeploymentEnvironment.DEVELOPMENT,
            strategy=DeploymentStrategy.ROLLING_UPDATE,
            nodes=[
                NodeConfiguration(
                    node_id="node-001",
                    role=NodeRole.COORDINATOR,
                    hostname="localhost",
                    ip_address="127.0.0.1",
                    port=8000,
                    cpu_cores=4,
                    memory_gb=8,
                    storage_gb=100
                )
            ],
            services=[
                ServiceConfiguration(
                    service_name="aegis-coordinator",
                    image="aegis/coordinator",
                    version="1.0.0",
                    replicas=1,
                    cpu_request="500m",
                    cpu_limit="1000m",
                    memory_request="512Mi",
                    memory_limit="1Gi",
                    ports=[8000, 8001],
                    environment_vars={
                        "NODE_ROLE": "coordinator",
                        "LOG_LEVEL": "INFO"
                    },
                    health_check={
                        "http": {
                            "path": "/health",
                            "port": 8000,
                            "initial_delay": 30,
                            "period": 10
                        }
                    }
                )
            ],
            network_config={
                "subnet": "172.20.0.0/16",
                "dns_servers": ["8.8.8.8", "8.8.4.4"]
            },
            security_config={
                "tls_enabled": True,
                "authentication_required": True
            },
            monitoring_config={
                "metrics_enabled": True,
                "logging_level": "INFO"
            }
        )
        
        # Ejecutar despliegue
        print("üìã Configuraci√≥n de despliegue creada")
        print(f"üéØ Estrategia: {deployment_config.strategy.value}")
        print(f"üåç Entorno: {deployment_config.environment.value}")
        print(f"üìä Servicios: {len(deployment_config.services)}")
        print(f"üñ•Ô∏è Nodos: {len(deployment_config.nodes)}")
        
        # Nota: En un entorno real, aqu√≠ se ejecutar√≠a el despliegue
        # success = await orchestrator.deploy(deployment_config)
        
        print("\n‚úÖ Demostraci√≥n del Orquestador de Despliegue completada")
        print("üìù Para ejecutar despliegue real, descomenta la l√≠nea de deploy()")
        
        return 0
        
    except Exception as e:
        logger.error(f"üí• Error en demostraci√≥n: {e}")
        return 1

if __name__ == "__main__":
    import sys
    exit_code = asyncio.run(main())
    sys.exit(exit_code)